# [Data augmentation](https://github.com/dipam7/fastai/blob/master/deep_learning/course1/lesson6/data-augmentation-in-fastai.ipynb)

Data augmentation refers to randomly applying various kinds of transforms to the images in our dataset. These transforms help introduce more variety in our dataset. They help transform an image like this

![Sample image](https://github.com/dipam7/fastai/blob/master/deep_learning/course1/lesson6/images/image_1.jpg)

into a bunch of images like these

![Sample image](https://github.com/dipam7/fastai/blob/master/deep_learning/course1/lesson6/images/image_2.png)

Find out more in the [article related to this notebook](https://medium.com/@dipam44/data-augmentations-in-fastai-84979bbcefaa)

# [Heatmaps and CNNs](https://github.com/dipam7/fastai/blob/master/deep_learning/course1/lesson6/heatmaps_and_CNNs.ipynb)
In this notebook, we learn all about CNN terminologies. We then learn about how to create a custom convolution and how to generate heatmaps. Heatmaps give us a visual representation of the parts of a picture the CNN looked at while making a prediction. Article out soon.

### Understanding CNNs
![Sample image](https://github.com/dipam7/fastai/blob/master/deep_learning/course1/lesson6/images/image_4.png)

### Manual CNN
![Sample image](https://github.com/dipam7/fastai/blob/master/deep_learning/course1/lesson6/images/image_5.png)

### Generating heatmaps
![Sample image](https://github.com/dipam7/fastai/blob/master/deep_learning/course1/lesson6/images/image_6.png)



# [Dropout](https://becominghuman.ai/regularization-in-neural-networks-3b9687e1a68c)

In this article, we learn about an important regularization technique in neural networks known as dropout. We also review the technniques we've seen before like weight decay and data augmentation. Read [the article](https://becominghuman.ai/regularization-in-neural-networks-3b9687e1a68c) for more.

![Sample image](https://github.com/dipam7/fastai/blob/master/deep_learning/course1/lesson6/images/imgae_3.png)
